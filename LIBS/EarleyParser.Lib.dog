// EarleyParser.Lib.dog
///////////////////////////
/*
The easiest way you use this is to autogenerate rules and parser functions with stringStructs.

To use it manually:
        1. Create a parser:           me EParser: parser
        2. Initialize your grammar:   parser.populateGrammar()
        3. Register the start symbol (an int from your grammar) and the string or stream to parse:
                parser.initParseFromString(startSymbol, textIn)
          OR    parser.initParseFromStream(startSymbol, IOBufferIn)
        4. Run the parse:             parser.doParse()
        5. Check for parse errors:    if(parser.doesParseHaveError()){print("Parse Error:" + parser.errorMesg)}
        6. if there are no errors make sure the parse is resolved:
            Either have it resolved during parseing, which is slower but can enable stream parsing
            OR call resolve():        our stateRec: topItem <- parser.resolve(parser.lastTopLevelItem, "")
        7. Extract the parse to your data structure.
            Stringstructs can automatically write a function to do this:
               Allocate(structToFill)
               parser.Extract_<CLASSNAME>_to_<CLASSNAME>(topItem, structToFill)
            It is also possible to have the extraction done while parsing is happening for a streaming parse.

        For a non-streaming parse:
            * Initialize with parser.initParseFromString(startSymbol, textIn).
            * Call resolve after the parse (because it is faster to do so).
            * Extract the parse after resolve.

        For a streaming parse:
            * Initialize with parser.initParseFromStream(startSymbol, IOBufferIn). // The buffer need not be full
            * call setStreamingMode(true) to enable blocking on the buffer, in-parse resolving and signaling for an Extract thread.
            * Use a thread to put data into the buffer.
            * Make a thread to extract the data as it is parsed.

        Stringstructs will generate code to do the above:
            * For non-streaming parse it generates the parser member function:
                our myStruct: Parse_myStruct(string textIn)

            * For streaming parses it generates a class:
                struct ThreadedInfonParseAndExtractor

NOTE:
    The Earley parser by default resolves 'nullable' productions by going into them.
    * The reason for this choice is that extracting the data becomes easier to automate.
    * However, this is not as efficient, and a technique described in "Practical Earley Parsing (Aycock 2002)"
    * is available: After populating your grammar (i.e, after calling populateGrammar()), call setQuickParse(true)
    * This call will predetermine which productions are nullable and set a flag to modify the algorithm.

 */


struct production{
    flag: isTerm
    mode[parseSEQ, parseALT, parseREP, parseOPT, parseAUTO]: prodType
    me string: constStr
    me List<me int>: items
    flag: isNullable
    flag: nullabilityCalced
    me string: toStr(me int64: seqPos, me int64: originPos, me string[their list]: rnames) <- {
        me int: ProdType <- prodType
        me string: S <- ""
        me string: ProdStr <- ""
        S <+- "["
        if     (ProdType==parseALT) {ProdStr<-"ALT: "}
        else if(ProdType==parseAUTO){ProdStr<-"Aut: "}
        else if(ProdType==parseSEQ) {ProdStr<-"SEQ: "}
        else if(ProdType==parseREP) {ProdStr<-"REP: "}
        //S <+- ProdStr + " from slot:" + toString(originPos) + ": "
        S <+- toString(originPos) + ": "   // Show origin slot
        if(isTerm){
            if(seqPos==0) {S <+- " > "}
            S <+- '"' + constStr + '"'
            if(seqPos>0) {S <+- " > "}
        } else {
            if(ProdType==parseALT and seqPos==0) {S <+- " > "}
            withEach p in items {
                if(ProdType == parseSEQ and p_key == seqPos){ S <+- " > "}
                if(p_key!=0){
                    if(ProdType==parseALT){S <+- "| "}
                }
                if(ProdType==parseREP and p_key>0){S <+- p + " "}
                else {S <+- rnames[p] + " "}
            }
            if(ProdType==parseREP){ S <+- '(Len:%i`seqPos`)'}
            else {if (((p_key == seqPos and ProdType == parseSEQ) or (ProdType==parseALT and seqPos>0))) {S <+- " > "}}
        }
        if(isNullable){S<+-" -NBL"}
        S <+- "] "
        return(S)
    }
}

struct pedigree{
    our stateRec: pred
    our stateRec: cause
    me int: productionID
}

struct stateRec{
    me int: productionID
    me int64: SeqPosition
    me int64: originPos
    me int64: crntPos
    me List<me pedigree>: pedigrees
    our stateRec: next
    our stateRec: child
    flag: resolved
    flag: nextIsNull
    flag: fullyComplete
    me string: stringify(their EParser: EP) <- {
        me string: S <- ""
        their production: prod <- EP.grammar[productionID]
        S <+- prod.toStr(SeqPosition, originPos, EP.rnames)
        if(resolved){S<+-"-R"}
        if(fullyComplete){S<+-"-FC"}
        if(nextIsNull){S<+-"-NN"}
       // S <+- ":("+self.mySymbol(self)+")"
       return(S)
    }

flag: MARKer1  // Use these to mark staterecs in grapher
flag: MARKer2  // They are for debugging and can be removed
}

struct stateSets{
    me List<our stateRec>: stateRecs
}

struct EParser{
    their strBuf: streamToParse
    me int: startProduction
    me List<me stateSets>: SSets
    me List<me production>: grammar
    me bool: parseFound
    our stateRec: lastTopLevelItem
    our stateRec: topParseNode
    me int64: highestSlotSoFar
    me string: errorMesg
    me int64: errLineNum
    me int64: errCharPos
    me List<me string>: rnames

    me bool: streamingMode
    me Mutex: streamingSRecMutex
    me SyncLock: streamingSRecLock

    me bool: doQuickParse
    void: setQuickParse(me bool: doQuick) <- {
        doQuickParse <- doQuick
        if(doQuickParse){preCalcNullability()}
    }


    me char: getCharAt(me int64: pos) <- {
        me char: ch <- streamToParse.at(pos)
        topOffSSets()
        return(ch)
    }
    our strBufItr: getItrAt(me int64: pos) <- {
        our strBufItr: bufItr <- streamToParse.getItrAt(pos)
        topOffSSets()
        return(bufItr)
    }

    void: clearGrammar() <- {grammar.clear() rnames.clear()}
    void: addTerminalProd(me string: name, me int: ProdType, me string: s) <- {
        me production: P
        P.prodType  <- ProdType
        P.isTerm    <- true
        P.constStr  <- s
        P.isNullable<- (ProdType==parseAUTO and (name=="ws" or name=="wsc"))
        P.nullabilityCalced <- true
        grammar.pushLast(P)
        rnames.pushLast(name)
    }
    void: addNon_TermProd(me string: name, me int: ProdType, me List<me int>: terms) <- {
        me production: prod
        prod.prodType   <- ProdType
        prod.items      <- terms
        if(doQuickParse){
            if(prod.prodType==parseREP and prod.items[1]==0){prod.isNullable<-true; prod.nullabilityCalced <- true}
            else if(prod.prodType==parseSEQ and prod.items.size()==0){prod.isNullable<-true; prod.nullabilityCalced <- true}
            else if(prod.prodType==parseALT and prod.items.size()==0){prod.isNullable<-true; prod.nullabilityCalced <- true}
        }
        grammar.pushLast(prod)
        rnames.pushLast(name)
    }

    me bool: isNullableSet(their production: prod) <- {
        // This function muxt be called with completed grammar
        // and on the simplest productions first to avoid hanging
        me bool: retVal
        if(prod.nullabilityCalced){return(prod.isNullable)}
        if(prod.isTerm){
  //          if(prod.prodType==parseAUTO and (name=="ws" or name=="wsc")){retVal <- true}
        } else {
            if(prod.prodType==parseSEQ){
                retVal<-true
                withEach item in prod.items{
                    if(!isNullableSet(grammar[item])){retVal<-false; break()}
                }
            } else if(prod.prodType==parseALT){
                retVal<-false
                withEach item in prod.items{
                    if(isNullableSet(grammar[item])){retVal<-true; break()}
                }
            } else if(prod.prodType==parseREP){
                if(prod.items[1]==0 or isNullableSet(grammar[prod.items[0]])){retVal <- true}
            }
        }
        prod.isNullable <- retVal
        prod.nullabilityCalced<-true
        return(retVal)
    }

    void: preCalcNullability() <- {
        // This assumes very simple nullable productions are already marked
        // If you used add*Prod() to add them, they are.
        withEach prod1 in grammar{
            if(prod1.nullabilityCalced){continue()}
            if(!prod1.isTerm){
                if(prod1.prodType==parseSEQ){
                    me bool: checkable <-true
                    withEach item in prod1.items{
                        if(!grammar[item].nullabilityCalced){checkable<-false}
                    }
                    if(checkable){isNullableSet(prod1)}
                }else if(prod1.prodType==parseREP){
                    if(grammar[prod1.items[0]].nullabilityCalced){
                        isNullableSet(prod1)
                    }
                }
            }
        }
        withEach prod2 in grammar{
            isNullableSet(prod2)
        }
    }
    void: dump() <- {
        withEach crntPos in RANGE(0 .. SSets.size()) {
            their stateSets: SSet <- SSets[crntPos]
            me string: ch <- "x"
            if(crntPos+1 != SSets.size()) {
                ch <- streamToParse.atSafe(crntPos)
            }
            me string: logStr <- ""; me int64: tmp <- crntPos
            logStr <+- "SLOT: "+ toString(tmp)+"'"+ ch+ "' - size:\n"
            withEach SRec in SSet.stateRecs {
                logStr <+- SRec.mySymbol(SRec)+": "
                logStr <+- SRec.pedigrees[0].pred.mySymbol(SRec.pedigrees[0].pred)+": "
                logStr <+- SRec.pedigrees[0].cause.mySymbol(SRec.pedigrees[0].cause)+":"
                logStr <+- "    "+SRec.stringify(self)+"\n"
            }
            log(logStr)
        }
        if(parseFound){
            log("\nPARSE PASSED!")
            log("lastTopLevelItem:"+lastTopLevelItem.mySymbol(lastTopLevelItem)+"")
        }
        else {log("\nPARSE failed.\n")}
    }

    void: addSRecToGrapher(our stateRec: SRec, me string: attrs) <-{
        me string: sRecSym <- SRec.mySymbol(SRec)
        grapher.addNode(sRecSym, SRec.stringify(self)+":"+SRec.mySymbol(SRec), attrs)
        grapher.setNodeSlot(sRecSym, toString(SRec.crntPos))
    }

    void: dumpGraph(me string: title, me int: layout) <- {
        grapher.clear()
        grapher.addItem("rankdir=LR;")
        me string[map string]: rankSlots
        me string: prevHeader <- ""
        withEach crntPos in RANGE(0 .. SSets.size()) {
            me int64: curPos <- crntPos
            their stateSets: SSet <- SSets[crntPos]
            me string: ch <- "x"
            if(crntPos+1 != SSets.size()) {
                ch <- streamToParse.atSafe(crntPos)
            }
            if(layout==0){
                me string: slotLabel <- "SLOT: "+ toString(curPos)+"'"+ ch +"'"
                grapher.addNode(slotLabel, "", "shape=box")
                rankSlots[toString(curPos)] <+- "\""+slotLabel+"\"; "
                if(prevHeader!=""){grapher.addEdge(prevHeader, slotLabel, "", "")}
                prevHeader <- slotLabel
            }
            withEach SRec in SSet.stateRecs {
                if(SRec.next==NULL and SRec.child==NULL){continue()}
                me string: sRecSym <- SRec.mySymbol(SRec)
                me string: rankID
                if(layout==0){rankID <- toString(curPos)}
                else if(layout==1){rankID <- toString(SRec.originPos)+":"+toString(SRec.productionID)}
                rankSlots[rankID] <+- "\""+sRecSym+"\"; "
                me string: lastTopAttrs <-""
                if(SRec===lastTopLevelItem){lastTopAttrs<-"style=filled fillcolor=lightblue"}
                if(SRec===topParseNode){lastTopAttrs<-"style=filled fillcolor=green"}
                if(SRec.MARKer1){lastTopAttrs<-"style=filled fillcolor=yellow"}
                if(SRec.MARKer2){lastTopAttrs<-"style=filled fillcolor=red"}
                grapher.addNode(sRecSym, SRec.stringify(self)+":"+SRec.mySymbol(SRec), lastTopAttrs)
                if(SRec.next!=NULL){grapher.addEdge(sRecSym, SRec.next.mySymbol(SRec.next), "next", "color=orange")}
                if(SRec.child!=NULL){grapher.addEdge(sRecSym, SRec.child.mySymbol(SRec.child), "child", "color=brown")}

                me int: count<-0
                withEach ped in SRec.pedigrees{
                    me string: cntStr <- ""
                    if(count>0){cntStr<-toString(count)}
                    if(ped.pred!=NULL){
                 //       grapher.addEdge(sRecSym, ped.pred.mySymbol(ped.pred), "pred"+cntStr, "color=blue")
                    }
                    if(ped.cause!=NULL){
                 //       grapher.addEdge(sRecSym, ped.cause.mySymbol(ped.cause), "cause"+cntStr, "color=darkgreen")
                    }
                    count <+- 1
                }
            }
            withEach rankItem in rankSlots: {
                me string: sameRank <- "{rank=same; " + rankItem + "}"
                grapher.addItem(sameRank)
            }
        }
        me string: filename <- grapher.deQuote(title)+".dot"
        grapher.saveGraph(title, filename) ; grapher.clear()
    }

    void: dumpResolvePath(our stateRec: SRec) <- {
        me int: curPos <- SRec.crntPos
        me string: sRecSym <- SRec.mySymbol(SRec)
        me string: ch <- streamToParse.atSafe(curPos)
        me string: nodeAttrs <-""
        addSRecToGrapher(SRec, nodeAttrs)
        me int: count<-0
        withEach ped in SRec.pedigrees{
            me string: cntStr <- ""
            if(count>0){cntStr<-toString(count)}
            if(ped.pred!=NULL){
                if(ped.pred.crntPos!=curPos){
                    grapher.addEdge(sRecSym, ped.pred.mySymbol(ped.pred), "pred"+cntStr, "color=darkgreen")
                    dumpResolvePath(ped.pred)
                }
            }
            if(ped.cause!=NULL){
                me string: pedCauseSym <- ped.cause.mySymbol(ped.cause)
                grapher.addEdge(sRecSym, pedCauseSym, "cause"+cntStr, "color=orange")
                addSRecToGrapher(ped.cause, "")
            }
            count <+- 1
        }
    }

    void: dumpParseTrace(me string: title, me int: charPos) <-{
        grapher.clear()
        grapher.addItem("rankdir=LR;")
        me int: curPos <- charPos
        their stateSets: SSet <- SSets[charPos]
        withEach SRec in SSet.stateRecs {
            dumpResolvePath(SRec)
        }

        me string: filename <- grapher.deQuote(title)+".dot"
        grapher.saveGraph(title, filename) ; grapher.clear()
    }

    void: topOffSSets() <- {
        me int64: sizeDiff <- (streamToParse.size()+1) - SSets.size()
        if(sizeDiff>0){
            me stateSets: newSSet
            withEach i in RANGE(0 .. sizeDiff){
                SSets.pushLast(newSSet)
            }
        }
    }

    me int64: chkStr(me int64: pos, me string: s) <- {
        me int64: L <- s.size()
        our strBufItr: txtItr <- getItrAt(pos)
        withEach i in RANGE(0 .. L){
            if(txtItr == NULL or txtItr.status!=bfOK or txtItr.ch() != s[i]){return(-1)}
            txtItr.goNext()
        }
        return(L)
    }

    me int64: scrapeUntil(me int64: pos, me string:endStr) <- {
        me char: ender <- endStr[0]
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(ch==ender){
                me int64: p <- txtItr.crntAbsPos()
                me int64: nxtLen <- chkStr(p, endStr)
                if(nxtLen>0){return((p+nxtLen)-pos)}
            }
            txtItr.goNext()
        }
        return(-1)
    }

    me int64: escapedScrapeUntil(me int:pos, me string:endChar) <- {
        me string: prevCharStr <- " "
        me char: prevChar <- prevCharStr[0]
        me char: ender <- endChar[0]
        me string: escCharStr <- "\\ "
        me char: escChar <- escCharStr[0]
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            me int64: p <- txtItr.crntAbsPos()
            if(prevChar!=escChar and ch==ender){return(p-pos)}
            if(prevChar==escChar and ch==escChar) {prevChar<-escCharStr[1]}
            else {prevChar <- ch}
            txtItr.goNext()
        }
        return(-1)
    }

    me int64: scrapeAlphaSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isalpha(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeUintSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isdigit(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeHexNum(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isxdigit(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeBinNum(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isxdigit(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeAlphaNumSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isalnum(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeAlphaNum_Seq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if (!(isalnum(ch) or ch=="_")){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }

    me int64: scrapePrintableSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isprint(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }

    me int64: scrapeCComment(me int:pos) <- {
        me char: ch <- getCharAt(pos)
        if(ch=="/"){
            me char: nextCh <- getCharAt(pos+1)
            if(nextCh=="/"){
                return(scrapeToEOL(pos))
            } else if(nextCh=="*"){
                return(scrapeUntil(pos+2, "*/")+2)
            }
        }
        return(0)
    }

    me int64: scrapeWSC(me int64: pos) <- {
        me int64: charsUsed <- 0
        me int64: p <- pos
        while(true){
            me int64: prevP <- p
            me char: ch <- getCharAt(p)
            if(isspace(ch)){p <+- 1; charsUsed <+- 1}
            else if(ch=="/"){
                me int64: cmntLen <- scrapeCComment(p)
                if(cmntLen>0){p <+- cmntLen; charsUsed <+- cmntLen}
            }
            if(prevP == p){  // !WSC(ch)
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
        }
        return(0) // Never reached
    }
    me int64: scrapeWS(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isspace(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }

    me int64: scrapeQuotedStr(me int64: pos) <- {
        me string: ch <- ""
        ch <+- getCharAt(pos)
        if(ch != "\'" and ch != "\""){return(-1)}
        else{pos <+- 1}
        me int64: sLen <- escapedScrapeUntil(pos, ch)
        if(sLen<0){return(-1)}
        return(sLen+2)
    }

    me int64: scrapeQuotedStr1(me int64: pos) <- {
        if(chkStr(pos, "'")>=0){pos <- pos+1}else{return(-1)}
        me int64: sLen <- escapedScrapeUntil(pos, "'")
        if(sLen<0){return(-1)}
        return(sLen+2)
    }

    me int64: scrapeQuotedStr2(me int64: pos) <- {
        if(chkStr(pos, "\"")>=0){pos <- pos+1}else{return(-1)}
        me int64: sLen <- escapedScrapeUntil(pos, "\"")
        if(sLen<0){return(-1)}
        return(sLen+2)
    }
    me int64: scrapeCID(me int64: pos) <- {
        me char: ch <- getCharAt(pos)
        if(isalpha(ch)){
            return(scrapeAlphaNum_Seq(pos))
        }
        return(-1)
    }
    // TODO: me int64: scrapeUniID(me int64: pos) <- { }

    me int64: scrapeIntSeq(me int64: pos) <- {
        me int64: initialChars <- 0
        me char: ch <- getCharAt(pos)
        if(ch=="+" or ch=="-"){initialChars <- 1}
        me int64: numDigits <- scrapeUintSeq(pos+initialChars)
        if(numDigits>0){return(numDigits+initialChars)}
        return(-1)
    }
    // TODO: me int64: scrapeRdxSeq(me int64: pos) <- { }

    me int64: scrapeToEOL(me int64: pos) <- {
        return(scrapeUntil(pos, "\\n"))
    }
    me int64: textMatches(me int: ProdID, me int64: pos) <- {
        their production: Prod <- grammar[ProdID]
 //       print('    MATCHING "%s`Prod->constStr.data()`"... ')
        me int: prodType <- Prod.prodType
        if(prodType==parseSEQ){ //prod is simple text match
            return(chkStr(pos, Prod.constStr))
        } else{
            if(prodType==parseAUTO){
                switch(ProdID){
                    case alphaSeq:    {return(scrapeAlphaSeq(pos))}
                    case uintSeq:     {return(scrapeUintSeq(pos))}
                    case alphaNumSeq: {return(scrapeAlphaNumSeq(pos))}
                    case printables:  {return(scrapePrintableSeq(pos))}
                    case ws:          {return(scrapeWS(pos))}
                    case wsc:         {return(scrapeWSC(pos))}
                    case quotedStr:   {return(scrapeQuotedStr(pos))}
                    case quotedStr1:  {return(scrapeQuotedStr1(pos))}
                    case quotedStr2:  {return(scrapeQuotedStr2(pos))}
                    case HexNum_str:  {return(scrapeHexNum(pos))}
                    case BinNum_str:  {return(scrapeBinNum(pos))}
                    case BigInt:      {return(scrapeUintSeq(pos))}
                    case CID:         {return(scrapeCID(pos))}
             //       case UniID:       {return(scrapeUniID(pos))}
                    case intSeq:      {return(scrapeIntSeq(pos))}
             //       case RdxSeq:      {return(scrapeRdxSeq(pos))}
                    case toEOL:       {return(scrapeToEOL(pos))}
                    default: {print("Invalid AUTO-parse production type.\n")}
                }
            }
        }
        return(-1)
    }

    our stateRec: addProductionToStateSet(me int64: crntPos, me int: productionID, me int64: seqPos, me int64: origin, our stateRec: pred, our stateRec: cause) <- {
        me bool: Duplicate <- false
        our stateRec: newStateRecPtr
        their production: prod <- grammar[productionID]
        me int: ProdType <- prod.prodType
        if(crntPos > highestSlotSoFar){highestSlotSoFar <- crntPos}
        withEach item in SSets[crntPos].stateRecs { // Don't add duplicates.
            // TODO: change this to be faster. Not a linear search.
            if(item.productionID==productionID and item.originPos==origin){
                if(item.SeqPosition==seqPos){// or (ProdType==parseREP and item.SeqPosition+1 == seqPos)){
                    item.pedigrees.pushLast(pedigree(pred, cause, productionID))
                    newStateRecPtr <- item
                    Duplicate <- true
                }
            }
        }

        if(!Duplicate){
            if(ProdType == parseSEQ or ProdType == parseREP or ProdType == parseALT or ProdType == parseAUTO){
                Allocate(newStateRecPtr, productionID, seqPos, origin, crntPos)
                newStateRecPtr.pedigrees.pushLast(pedigree(pred, cause, productionID))
                if(productionID==startProduction and origin==0) {lastTopLevelItem <- newStateRecPtr}
                SSets[crntPos].stateRecs.pushLast(newStateRecPtr)
                if(!doQuickParse){applyPartialCompletion(newStateRecPtr)}
            }

            if(ProdType == parseALT and seqPos==0){
                withEach AltProd in prod.items {
                    addProductionToStateSet(crntPos, AltProd, 0, origin, newStateRecPtr, cause)
                }
            } else if(ProdType == parseAUTO and (productionID == ws or productionID == wsc) and seqPos==0){  // Whitespace is nullable
                addProductionToStateSet(crntPos, productionID, 1, origin, pred, cause)
            }
        }
        return(newStateRecPtr)
    }

    ///////////////// Late Completion Code
    //  This code handles the case where productions are added with the same origin (crntPos) as their (null) predecessor and must have completions applied from past completions.
    me List<our stateRec>: SRecsToComplete
    me int64: crntPos

    void: resetCompletions(me int64: CrntPos) <- {
        SRecsToComplete.clear()
        crntPos <- CrntPos
    }

    void: registerCompletion(our stateRec: SRecToComplete) <- {
        SRecsToComplete.pushLast(SRecToComplete)
    }

    our stateRec: applyCompletion(our stateRec: SRec, our stateRec: backSRec) <- {
        me int: backSRecProductionID <- backSRec.productionID
        me int64: backSRecOriginPos  <- backSRec.originPos
        me int64: backSRecSeqPos     <- backSRec.SeqPosition
        their production: backProd   <- grammar[backSRec.productionID]
        me int: prodTypeFlag         <- backProd.prodType
        if(prodTypeFlag==parseREP){
            me int: MAX_ITEMS  <- backProd.items[2]
            if((backSRecSeqPos < MAX_ITEMS or MAX_ITEMS==0) and backProd.items[0] == SRec.productionID ){//log(" ADVANCING REP: ")
                return(addProductionToStateSet(crntPos, backSRecProductionID, backSRecSeqPos+1, backSRecOriginPos, backSRec, SRec))
            }// else{log(" TOO MANY REPS")}
        } else if(prodTypeFlag==parseSEQ){
            if(backSRecSeqPos < backProd.items.size() and backProd.items[backSRecSeqPos] == SRec.productionID){//log(" ADVANCING SEQ: ")
                return(addProductionToStateSet(crntPos, backSRecProductionID, backSRecSeqPos+1, backSRecOriginPos, backSRec, SRec))
            }// else{log(" SEQ is NOT ADVANCING")}
        } else if(prodTypeFlag==parseALT){
            if(backSRecSeqPos == 0){
                withEach backAltProdID in backProd.items {
                    if(backAltProdID==SRec.productionID){//log(" ADVANCING ALT: ")
                        return(addProductionToStateSet(crntPos, backSRecProductionID, backSRecSeqPos+1, backSRecOriginPos, backSRec, SRec))
                    }//else{if(backAltProdID_key){log(" SKIP ALT")}
                }
            }
        }
        return(NULL)
    }

    void: applyPartialCompletion(our stateRec: backSRec) <- {
        withEach SRec in SRecsToComplete{
            if(SRec.originPos==crntPos and !(backSRec.productionID==SRec.productionID and backSRec.SeqPosition==SRec.SeqPosition and backSRec.originPos==SRec.originPos)){
                our stateRec: newSRec <- applyCompletion(SRec, backSRec)
            }
        }
    }

    me bool: checkException(our stateRec: SRec) <-{
// Use this function to alllow the start of the first infon to begin parsing to get streaming going.
        if(SRec.productionID==infon_str and SRec.originPos==0){return(true)}
        if(SRec.productionID==funcParts_str){return(true)}
       // if(SRec.productionID==pureInfon_str_ALT16_ALT23_SEQ24 and SRec.SeqPosition==4){return(true)}
        return(false)
    }
me int: numMarked
    void: complete(our stateRec: SRec, me int64: crntPos) <- {
        me int: productionID <- SRec.productionID
        me int64: originPos  <- SRec.originPos
        me bool: fullyComplete
        if(streamingMode and !SRec.fullyComplete){
            fullyComplete <- true
            if(!(streamToParse.bufferClosed and crntPos==SSets.size()-1)){ // Detect done due to EOB
                withEach SRidx in RANGE(crntPos .. highestSlotSoFar+1){
                    their stateSets: SSetR  <- SSets[SRidx]
                    withEach fSrec in SSetR.stateRecs {
                        me string: attrs
                        if((fSrec.productionID==productionID and fSrec.originPos==originPos)){ // and !checkException(fSrec)){
                            if(!(SRec===fSrec) and !grammar[fSrec.productionID].isNullable){
                                attrs <- "color=red"
                      //  log("STOPPER: "+fSrec.stringify(self) + "  STOPed: "+SRec.stringify(self))
                                fullyComplete <- false; break()}
                        }
                    }
                }
            }
            if(fullyComplete and !grammar[productionID].isTerm){
                SRec.fullyComplete<-true
                SRec.MARKer1 <- true
           //     dumpParseTrace("complete"+toString(numMarked), highestSlotSoFar)
           ///     numMarked <+- 1; log("MARKED:"+toString(numMarked) + SRec.stringify(self))
                resolve(SRec, "")
            }
        }
        //me string: allDone; if(fullyComplete){allDone<-": ALL_DONE"} log("        COMPLETING: " + SRec.stringify(self) + allDone)

        if(productionID==startProduction and originPos==0){
            parseFound <- true
        }

        if(!doQuickParse){registerCompletion(SRec)}
        their stateSets: SSet  <- SSets[originPos]
        me int: count <- 0
        our stateRec: lastBackRec
        our stateRec: newSRec
        withEach backSRec in SSet.stateRecs {
            if(!(crntPos==originPos and backSRec.productionID==productionID and backSRec.SeqPosition==SRec.SeqPosition and backSRec.originPos==originPos)){
                newSRec <- applyCompletion(SRec, backSRec)
                if(newSRec!=NULL){count <+- 1; lastBackRec<-backSRec}
            }
        }
        if(count==1 and SRec.fullyComplete){
          /*  lastBackRec.fullyComplete <- true
            lastBackRec.next <- newSRec
            lastBackRec.MARKer2 <- true
            resolve(lastBackRec, "#")*/
            if(newSRec!=NULL){
             //   newSRec.fullyComplete <- true
                newSRec.MARKer2 <- true
             //   resolve(newSRec, "#")
            }
        }
    }

    me bool: ruleIsDone(me bool: isTerminal, me int64: seqPos, me int: ProdType, me int: numItems)<-{
        if(isTerminal and seqPos==1) {return(true)}
        if(!isTerminal){
            if(ProdType==parseSEQ and seqPos==numItems) {return(true)}
            if(ProdType==parseALT and seqPos==1) {return(true)}
        }
        return(false)
    }

    void: doParse() <- {
      //  grapher.clear()
        parseFound <- false
        me int64: crntPos <- 0
        streamToParse.at(crntPos) // Wait for buffer to fill
        while(crntPos<SSets.size()){
            their stateSets: SSet <- SSets[crntPos]

     //       log("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   PROCESSING SLOT: " + toString(crntPos)+ " '" + streamToParse.atSafe(crntPos)+"'")

     //     if(streamingMode){dumpGraph("ProcessingSlot"+toString(crntPos), 1)}
            resetCompletions(crntPos)
            withEach SRec in SSet.stateRecs {
                their production: prod <- grammar[SRec.productionID]
                me int: ProdType       <- prod.prodType
                me bool: isTerminal    <- prod.isTerm != 0
                me int64: seqPos       <- SRec.SeqPosition
     //         log("PARSE:"+SRec.stringify(self) + " SYM:" + SRec.mySymbol(SRec))
                if(ruleIsDone(isTerminal, seqPos, ProdType, prod.items.size())){
                    complete(SRec, crntPos) // COMPLETER for non-REPetitions
                }else{
                    if(isTerminal){ // SCANNER: Scanning means Testing for a Matching terminal
                        me int64: len <- textMatches(SRec.productionID, crntPos)
                        if(len>=0){ // if match succeeded
                            addProductionToStateSet(crntPos+len, SRec.productionID, 1, crntPos, SRec, NULL)
                        }
                    }else{ // non-terminal
                        if(ProdType == parseREP){
                            me int: MIN_ITEMS <- prod.items[1]
                            me int: MAX_ITEMS <- prod.items[2]
                            me bool: must_be   <- seqPos < MIN_ITEMS
                            me bool: cannot_be <- seqPos > MAX_ITEMS and (MAX_ITEMS!=0)
                            if(!must_be){ // COMPLETER for REPetitions
                                complete(SRec, crntPos)
                                addProductionToStateSet(crntPos, prod.items[0], 0, crntPos, SRec, NULL) // Tentative
                            } else if(!cannot_be){ // PREDICTOR for REPetitions
                                our stateRec: newItm1 <- addProductionToStateSet(crntPos, prod.items[0], 0, crntPos, SRec, NULL)
                                if(doQuickParse and grammar[prod.items[0]].isNullable){
                                    our stateRec: newItm <- addProductionToStateSet(crntPos, SRec.productionID, seqPos+1, SRec.originPos, SRec, NULL)
                                }
                            }
                        } else { // PREDICTOR for SEQ and ALT
                            our stateRec: newItm1 <- addProductionToStateSet(crntPos, prod.items[seqPos], 0, crntPos, SRec, NULL)  // Add a cause SEQ with cursor at the very beginning. (0)
                            if(doQuickParse and grammar[prod.items[seqPos]].isNullable){
                                our stateRec: newItm <- addProductionToStateSet(crntPos, SRec.productionID, seqPos+1, SRec.originPos, SRec, NULL)
                            }
                        }
                    }
                }
            }
          if(streamingMode){dumpParseTrace("ParseTraceAt"+toString(crntPos), crntPos)}
            crntPos <+- 1
        }
      //  log("GRAPHING")
      //  grapher.saveGraph("Parse Tree", "parseTree.dot"); grapher.clear()
    }

    void: countLinesToCharPos(me int64: charPos) <- {
        errLineNum <- 1
        me int64: lastLinePos <- 0
        withEach C in RANGE(0..charPos){
            me char: ch <- streamToParse.at(C)
            if(ch == "\n"){
                errLineNum <- errLineNum+1
                lastLinePos <- C
            }
        }
        errCharPos <- charPos-lastLinePos+1
    }

    me bool: doesParseHaveError() <- {
  //      logMesg("\n\nChecking for Parse Errors...\n")
        errorMesg <- ""
        me int64: lastSSetIDX <- SSets.size()
        me int64: lastPosWithItems <- 0
        withEach ssetIDX in Backward RANGE(0 .. lastSSetIDX){
            their stateSets: SSet <- SSets[ssetIDX]
            me int64: numItems <- SSet.stateRecs.size()
            if(numItems>0 and lastPosWithItems==0){lastPosWithItems <- ssetIDX}
         //   print("Position ", ssetIDX, " has ", numItems, "items.\n")
        }
  //      print("lastPosWithItems:", lastPosWithItems, "\n")

        their stateSets: lastSSet <- SSets[lastPosWithItems]

        me int64: lastSRecIDX <- lastSSet.stateRecs.size()-1
        our stateRec: lastSRec // <- lastSSet.stateRecs[lastSRecIDX]
        their production: prod
        me int: ProdType <- 0
        me int: isTerminal<- 0
        me int64: seqPos<- 0
      //  lastSRec.stringify(self) print("\n----\n")

        withEach SRec in lastSSet.stateRecs {
            lastSRec <- SRec
            prod <- grammar[SRec.productionID]
            ProdType <- prod.prodType
            isTerminal <- prod.isTerm
            seqPos <- SRec.SeqPosition
            if (SRec.productionID==startProduction and SRec.originPos==0 and ((lastPosWithItems+1)==lastSSetIDX) and seqPos==prod.items.size()){
 //               print("Passed\n")  // !!!!!!!!!!!!!!!!!!! This tells when the parse passes.
                return(false)
            }
            //SRec.stringify(self)
        }

        //lastSRec.stringify(self) print("\n----\n", seqPos)
        if(isTerminal!=0){
            if(seqPos==0){
                errorMesg <- "Expected '" + prod.constStr + "'"
                countLinesToCharPos(lastPosWithItems)
            }
        }

        if(errorMesg=="" and (lastPosWithItems+1)!=lastSSetIDX){
            errorMesg<-'Parse failed for unknown reason.'
        }
        if(errorMesg=="") {return(false)}
        else {return(true)}
    }

    me int: choosePedigreeToFollow(me int: prodID, me pedigree[their list]: peds) <- {
        return(0)
    }

    me int: numResolutions
    our stateRec: resolve(our stateRec: SRec, me string: indent) <- {
        if(SRec == NULL){print("\nStateRecPtr is null.\n\n") exit(1)}
        our stateRec: crntRec <- SRec
        me int64: seqPos <- crntRec.SeqPosition
        me int: prodID <- crntRec.productionID
        their production: Prod <- grammar[prodID]
 //       print(indent+'grammar[%i`prodID`] = ')  crntRec.stringify(self)  print("\n", indent, "\n")
        if(Prod.isTerm){
    //        log(indent+" RESOLVE-TERM:"+crntRec.stringify(self) + " SYM:" + crntRec.mySymbol(crntRec))
            if(crntRec.pedigrees.size()>0){
                me pedigree: ped <- crntRec.pedigrees[0]
                our stateRec: pedSR <- ped.pred
               // if(pedSR!=NULL){log(indent+"       ped.pred:"+pedSR.stringify(self) + " SYM:" + pedSR.mySymbol(pedSR))}
                pedSR <- ped.cause
              //  if(pedSR!=NULL){log(indent+"       ped.cause:"+pedSR.stringify(self) + " SYM:" + pedSR.mySymbol(pedSR))}
            } else{log("NO_PED")}



        } else if(seqPos>0){
            withEach subItem in Backward RANGE(0..seqPos){ //+1){
                me bool: doneTheRestAlready <- false
            //    log(toString(numResolutions)+indent+" RESOLVE:"+crntRec.stringify(self) + " SYM:" + crntRec.mySymbol(crntRec))
                if(!crntRec.resolved){numResolutions <+- 1}
                me int: pedToFollow <- choosePedigreeToFollow(prodID, crntRec.pedigrees)
                me pedigree: ped <- crntRec.pedigrees[pedToFollow]

             //   if(ped.pred==NULL){crntRec.nextIsNull<-true}
             //   else{
                    if(ped.pred.next==NULL){
                        ped.pred.next <- crntRec
                        //log("SET_NEXT of"+ped.pred.mySymbol(ped.pred)+" to "+crntRec.child .mySymbol(crntRec.next))
                    } else{doneTheRestAlready <- true}
             //   }

                if(!crntRec.resolved){
                    if(ped.cause != NULL){
                        crntRec.child <- resolve(ped.cause, indent+"|    ")
                        //log("SET_CHILD of"+crntRec.mySymbol(crntRec)+" to "+crntRec.child .mySymbol(crntRec.child) + "   CAUSE:"+ped.cause.mySymbol(ped.cause))
                    }
                }
              //  if(doneTheRestAlready){break()} //TODO: this could save some extra calls.
                crntRec <- ped.pred
            }
        }
        if(streamingMode){
            me MutexMngr: MtxMgr{streamingSRecMutex}
            SRec.resolved <- true
            streamingSRecLock.notifyOne()
        }
   //     sleep(100)  //TODO: Test streaming mode with this uncommented
        SRec.resolved <- true
        return(crntRec)
    }

    void: docPos(me int: indent, our stateRec: SRec, me string: tag) <- {
        withEach i in RANGE(0 .. indent){ print("|    ")}
        if(SRec){
            print(SRec.stringify(self))
        } else {print(" NULL ")}
        print("  \t", tag, "\n")
    }

    void: displayParse(our stateRec: SRec, me string: indent) <- {
        their production: prod <- grammar[SRec.productionID]
        if(prod.isTerm){
            print(indent, "'")
            withEach i in RANGE(SRec.originPos .. SRec.crntPos){
                print(streamToParse.at(i))
            }
            print("'\n")
        } else {
           // print(indent) SRec.stringify(self) print("\n")
            if(SRec.child){
                displayParse(SRec.child, indent+"   | ")
            }
            if(SRec.next){
                displayParse(SRec.next, indent)
            }
        }
    }

    me string: makeStr(our stateRec: SRec) <- {
        me string: S <- ""
        me int64: startPos <- SRec.originPos
        me int64: endPos <- SRec.crntPos
        me int: prod <- SRec.productionID
        if(prod == quotedStr or prod == quotedStr1 or prod == quotedStr2){
            startPos <- startPos+1
            endPos <- endPos-1
        }
        our strBufItr: txtItr <- streamToParse.getItrAt(startPos)
        while(txtItr != NULL and txtItr.status==bfOK and txtItr.crntAbsPos()<endPos){
            me char: ch <- txtItr.ch()
            S <- S+ch
            txtItr.goNext()
        }
        return(S)
    }
    me int64: makeInt(our stateRec: SRec) <- {
        me string: S <- makeStr(SRec)
        me int64: N <- stol(S)
        return(N)
    }
    me BigInt: makeHexInt(our stateRec: SRec) <- {
        me string: S <- makeStr(SRec)
        me BigInt: N
        N.hexNumToBigInt(S)
        return(N)
    }
    me BigInt: makeBinInt(our stateRec: SRec) <- {
        me string: S <- makeStr(SRec)
        me BigInt: N
        N.binNumToBigInt(S)
        return(N)
    }
    our stateRec: getNextStateRec(our stateRec: SRec) <- {
        if(streamingMode){
            me MutexMngr: MtxMgr{streamingSRecMutex}
            log("WAIT(GetNExtStateRec) for:"+SRec.stringify(self) + " SYM:" + SRec.mySymbol(SRec))
            while(SRec.next==NULL and !SRec.nextIsNull){
                streamingSRecLock.wait(MtxMgr)
                log("DONE_WAITING?(GetNExtStateRec)")
            }
            if(SRec.next==NULL){log("SREC==NULL")}
            if(!SRec.nextIsNull){log("!SRec.nextIsNull")}
            if(SRec.next){log("GNSR:"+SRec.stringify(self)+"  "+SRec.mySymbol(SRec)  +  "  .NEXT:"+SRec.next.stringify(self)+"  "+SRec.next.mySymbol(SRec.next));}else{log("GNSR: NULL")}
            return(SRec.next)
        }
       // if(SRec.next){log("GNSR:"+SRec.stringify(self)+"  "+SRec.mySymbol(SRec)  +  "  .NEXT:"+SRec.next.stringify(self)+"  "+SRec.next.mySymbol(SRec.next));}else{log("GNSR: NULL")}
        return(SRec.next)
    }

    our stateRec: initParseFromStream(me int: startProd, their strBuf: streamBuffer) <- {
        streamToParse <- streamBuffer
        startProduction <- startProd
        highestSlotSoFar<- 0
        SSets.clear()
        topOffSSets()
        topParseNode <- addProductionToStateSet(0, startProduction, 0, 0, NULL, NULL)
        return(topParseNode)
    }

    our stateRec: initParseFromString(me int: startProd, me string: txt) <- {
        // print('Will parse "', txt, '" with rule ', startProd, '.\n')
        their strBuf:: bufToParse
        bufToParse.init()
        bufToParse.putStr(txt)
        bufToParse.close()
        our stateRec: topParseNode <- initParseFromStream(startProd, bufToParse)
        return(topParseNode)
    }
    void: setStreamingMode(me bool: streamMode) <- {streamingMode <- streamMode}
}
